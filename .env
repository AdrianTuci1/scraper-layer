# ===========================================
# Scraper Layer - Environment Configuration
# ===========================================
# Copy this file to .env and fill in your values

# ===========================================
# Common Configuration
# ===========================================
NODE_ENV=production
STAGE=prod
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_access_key_here
AWS_SECRET_ACCESS_KEY=your_secret_key_here

# ===========================================
# Node.js API Service Configuration
# ===========================================
# Server Configuration
PORT=3000
LOG_LEVEL=info
RATE_LIMIT_MAX=100
ALLOWED_ORIGINS=http://localhost:3000,https://yourdomain.com

# API Configuration
API_KEY=your_32_character_api_key_here

# AWS Resources for Node.js API
DYNAMODB_JOBS_TABLE=scraper-jobs
DYNAMODB_PIPELINES_TABLE=scraper-pipelines
SQS_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/your-account/scraper-queue
S3_BUCKET=scraper-results-bucket

# ===========================================
# Go Scraper Engine Configuration
# ===========================================
# SQS Configuration
SQS_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/123456789012/scraper-queue

# S3 Configuration
S3_BUCKET_NAME=scraper-results-bucket

# Node.js API Configuration
NODE_API_URL=http://scraper-node:3000/api

# Worker Configuration
MAX_CONCURRENT_JOBS=100
WORKER_POOL_SIZE=10

# Logging
LOG_LEVEL=info
LOG_FORMAT=json

# Proxy Configuration (optional)
PROXY_LIST=proxy1:port,proxy2:port
USE_PROXY_ROTATION=false

# Retry Configuration
MAX_RETRIES=3
RETRY_DELAY=5s

# ===========================================
# Docker Compose Specific
# ===========================================
# These variables are used by docker-compose.yml
# Make sure to set the correct values for your environment
